{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from semantic_text_similarity.models import WebBertSimilarity\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model: web-bert-similarity from https://github.com/AndriyMulyar/semantic-text-similarity/releases/download/v1.0.0/web_bert_similarity.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 405359924/405359924 [01:30<00:00, 4459113.78B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download model: web-bert-similarity\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\ikath\\\\AppData\\\\Local\\\\Temp\\\\tmp0gf0gf5d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m web_model \u001b[38;5;241m=\u001b[39m \u001b[43mWebBertSimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\semantic_text_similarity\\models\\bert\\web_similarity.py:7\u001b[0m, in \u001b[0;36mWebBertSimilarity.__init__\u001b[1;34m(self, device, batch_size, model_name)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb-bert-similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, bert_model_path\u001b[38;5;241m=\u001b[39mmodel_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\semantic_text_similarity\\models\\util.py:40\u001b[0m, in \u001b[0;36mget_model_path\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download model: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m model_name)\n\u001b[0;32m     39\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(model_path)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m     43\u001b[0m temp_file\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m     44\u001b[0m temp_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\semantic_text_similarity\\models\\util.py:36\u001b[0m, in \u001b[0;36mget_model_path\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     http_get(model_url, temp_file)\n\u001b[1;32m---> 36\u001b[0m     tar \u001b[38;5;241m=\u001b[39m \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download model: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m model_name)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\tarfile.py:1622\u001b[0m, in \u001b[0;36mTarFile.open\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1620\u001b[0m     saved_pos \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, fileobj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ReadError, CompressionError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1624\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomptype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\tarfile.py:1688\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompressionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip module is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\gzip.py:174\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    172\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\ikath\\\\AppData\\\\Local\\\\Temp\\\\tmp0gf0gf5d'"
     ]
    }
   ],
   "source": [
    "web_model = WebBertSimilarity(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_model.predict([(\"She won an olympic gold medal\",\"The women is an olympic champion\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_model.predict([(\"anxiety\",\"nervous\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = \"public/datasets/disease and symptoms/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"users\":[]}\n",
    "with open('DATA.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename='DATA.json'):\n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"users\"].append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 4)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(DATASETS_DIR + 'Training.csv').dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
       "0        1          1                     1                    0          0   \n",
       "1        0          1                     1                    0          0   \n",
       "2        1          0                     1                    0          0   \n",
       "3        1          1                     0                    0          0   \n",
       "4        1          1                     1                    0          0   \n",
       "\n",
       "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
       "0       0           0             0        0                 0  ...   \n",
       "1       0           0             0        0                 0  ...   \n",
       "2       0           0             0        0                 0  ...   \n",
       "3       0           0             0        0                 0  ...   \n",
       "4       0           0             0        0                 0  ...   \n",
       "\n",
       "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
       "0           0         0             0                    0   \n",
       "1           0         0             0                    0   \n",
       "2           0         0             0                    0   \n",
       "3           0         0             0                    0   \n",
       "4           0         0             0                    0   \n",
       "\n",
       "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
       "0                     0                   0        0                     0   \n",
       "1                     0                   0        0                     0   \n",
       "2                     0                   0        0                     0   \n",
       "3                     0                   0        0                     0   \n",
       "4                     0                   0        0                     0   \n",
       "\n",
       "   yellow_crust_ooze         prognosis  \n",
       "0                  0  Fungal infection  \n",
       "1                  0  Fungal infection  \n",
       "2                  0  Fungal infection  \n",
       "3                  0  Fungal infection  \n",
       "4                  0  Fungal infection  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4920, 133)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itching                        0\n",
       "skin_rash                      1\n",
       "nodal_skin_eruptions           0\n",
       "continuous_sneezing            0\n",
       "shivering                      0\n",
       "                          ...   \n",
       "inflammatory_nails             0\n",
       "blister                        1\n",
       "red_sore_around_nose           1\n",
       "yellow_crust_ooze              1\n",
       "prognosis               Impetigo\n",
       "Name: 4919, Length: 133, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt=pd.read_csv(DATASETS_DIR + 'Testing.csv').dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fungal infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GERD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chronic cholestasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Drug Reaction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
       "0        1          1                     1                    0          0   \n",
       "1        0          0                     0                    1          1   \n",
       "2        0          0                     0                    0          0   \n",
       "3        1          0                     0                    0          0   \n",
       "4        1          1                     0                    0          0   \n",
       "\n",
       "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
       "0       0           0             0        0                 0  ...   \n",
       "1       1           0             0        0                 0  ...   \n",
       "2       0           0             1        1                 1  ...   \n",
       "3       0           0             0        0                 0  ...   \n",
       "4       0           0             1        0                 0  ...   \n",
       "\n",
       "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
       "0           0         0             0                    0   \n",
       "1           0         0             0                    0   \n",
       "2           0         0             0                    0   \n",
       "3           0         0             0                    0   \n",
       "4           0         0             0                    0   \n",
       "\n",
       "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
       "0                     0                   0        0                     0   \n",
       "1                     0                   0        0                     0   \n",
       "2                     0                   0        0                     0   \n",
       "3                     0                   0        0                     0   \n",
       "4                     0                   0        0                     0   \n",
       "\n",
       "   yellow_crust_ooze            prognosis  \n",
       "0                  0     Fungal infection  \n",
       "1                  0              Allergy  \n",
       "2                  0                 GERD  \n",
       "3                  0  Chronic cholestasis  \n",
       "4                  0        Drug Reaction  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "symp = []\n",
    "disease = []\n",
    "for i in range(len(df_tr)):\n",
    "    symp.append(df_tr.columns[df_tr.iloc[i]==1].to_list())\n",
    "    disease.append(df_tr.iloc[i,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['itching', 'skin_rash', 'nodal_skin_eruptions', 'dischromic _patches']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peptic ulcer diseae'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - get all symtpoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symp_col = list(df_tr.columns[:-1])\n",
    "def clean_symp(sym):\n",
    "    return sym.replace('_',' ').replace('.1','').replace('(typhos)','').replace('yellowish','yellow').replace('yellowing','yellow') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symp = [clean_symp(sym) for sym in (all_symp_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all symptoms which do not have a synset\n",
    "ohne_syns = []\n",
    "mit_syns = []\n",
    "for sym in all_symp:\n",
    "    if not wn.synsets(sym):\n",
    "        ohne_syns.append(sym)\n",
    "    else:\n",
    "        mit_syns.append(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mit_syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ohne_syns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sym(doc):\n",
    "    nlp_doc=nlp(doc)\n",
    "    d = []\n",
    "    for token in nlp_doc:\n",
    "        if not token.text.lower() in STOP_WORDS and token.text.isalpha():\n",
    "            d.append(token.lemma_.lower() )\n",
    "    return ' '.join(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stomach pain'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sym(\"skin peeling\")\n",
    "preprocess_sym(\"stomach paining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symp_pr = [preprocess_sym(sym) for sym in all_symp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associates each preprocessed symp with the name of its original column\n",
    "col_dict = dict(zip(all_symp_pr, all_symp_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - syntactic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_set(str1, str2):\n",
    "    list1 = str1.split(' ')\n",
    "    list2 = str2.split(' ')\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn similarity with the corpus\n",
    "def syntactic_similarity(symp_t, corpus):\n",
    "    most_sim = []\n",
    "    poss_sym = []\n",
    "\n",
    "    for symp in corpus:\n",
    "        d = pattern_set(symp_t, symp)\n",
    "        most_sim.append(d)\n",
    "\n",
    "    order = np.argsort(most_sim)[::-1].tolist()\n",
    "\n",
    "    for i in order:\n",
    "        if DoesExist(symp_t):\n",
    "            return 1, [corpus[i]]\n",
    "\n",
    "        if corpus[i] not in poss_sym and most_sim[i] != 0:\n",
    "            poss_sym.append(corpus[i])\n",
    "\n",
    "    if len(poss_sym):\n",
    "        return 1, poss_sym\n",
    "\n",
    "\n",
    "    else:\n",
    "        return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns all the subsets of this set. This is a generator.\n",
    "def powerset(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort list based on length\n",
    "def sort(a):\n",
    "    for i in range(len(a)):\n",
    "        for j in range(i+1,len(a)):\n",
    "            if len(a[j])>len(a[i]):\n",
    "                a[i],a[j]=a[j],a[i]\n",
    "    a.pop()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all permutations of a list\n",
    "def permutations(s):\n",
    "    permutations = list(itertools.permutations(s))\n",
    "    return([' '.join(permutation) for permutation in permutations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoesExist(txt):\n",
    "    txt=txt.split(' ')\n",
    "    combinations = [x for x in powerset(txt)]\n",
    "    sort(combinations)\n",
    "\n",
    "    for comb in combinations :\n",
    "        # print(permutations(comb))\n",
    "        for sym in permutations(comb):\n",
    "            if sym in all_symp_pr:\n",
    "                # print(sym)\n",
    "                return sym\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DoesExist('worried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nervous'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sym('really worried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_similarity(preprocess_sym('nervous'), all_symp_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern(inp,dis_list):\n",
    "    import re\n",
    "    pred_list=[]\n",
    "    ptr=0\n",
    "    patt = \"^\" + inp + \"$\"\n",
    "    regexp = re.compile(inp)\n",
    "    for item in dis_list:\n",
    "        if regexp.search(item):\n",
    "            pred_list.append(item)\n",
    "    if(len(pred_list)>0):\n",
    "        return 1,pred_list\n",
    "    else:\n",
    "        return ptr,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pattern('nail', all_symp_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV- Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "def WSD(word, context):\n",
    "    sens=lesk(context, word)\n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semanticD(doc1,doc2):\n",
    "    doc1_p=preprocess(doc1).split(' ')\n",
    "    doc2_p=preprocess_sym(doc2).split(' ')\n",
    "    score=0\n",
    "    for tock1 in doc1_p:\n",
    "        for tock2 in doc2_p:\n",
    "            syn1 = WSD(tock1,doc1)\n",
    "            syn2 = WSD(tock2,doc2)\n",
    "            #syn1=wn.synset(t)\n",
    "            if syn1 is not None and syn2 is not None :\n",
    "                x=syn1.wup_similarity(syn2)\n",
    "                if x is not None and x>0.1:\n",
    "                    score+=x\n",
    "    return score/(len(doc1_p)*len(doc2_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticD('anxiety', 'nervous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syna = wn.synsets('anxiety')\n",
    "syna[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synn = wn.synsets('nervous')\n",
    "synn[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synn[0].wup_similarity(syna[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_synsets = wn.synsets(\"brittle\") \n",
    "nervous_synsets = wn.synsets(\"nervous\") \n",
    "path = []\n",
    "wup = []\n",
    "lch = []\n",
    "\n",
    "for s1 in anxiety_synsets:\n",
    "    for s2 in nervous_synsets:\n",
    "        path.append(s1.path_similarity(s2))\n",
    "        wup.append(s1.wup_similarity(s2))\n",
    "\n",
    "pd.DataFrame([path, wup], [\"path\", \"wup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarite sem avec ts le corpus\n",
    "def semantic_similarity(symp_t,corpus):\n",
    "    max_sim=0\n",
    "    most_sim=None\n",
    "    for symp in corpus:\n",
    "        d=semanticD(symp_t,symp)\n",
    "        if d>max_sim:\n",
    "            most_sim = symp\n",
    "            max_sim = d\n",
    "\n",
    "    return max_sim, most_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_similarity('nervous', all_symp_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symp_pr.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symp_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "def suggest_syn(sym):\n",
    "    symp = []\n",
    "    synonyms = wordnet.synsets(sym)\n",
    "    lemmas=[word.lemma_names() for word in synonyms]\n",
    "    lemmas = list(set(chain(*lemmas)))\n",
    "    for e in lemmas:\n",
    "        res,sym1=semantic_similarity(e,all_symp_pr)\n",
    "        if res != 0:\n",
    "            symp.append(sym1)\n",
    "    return list(set(symp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggest_syn('worried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoit client_symptoms et renvoit un dataframe avec 1 pour les symptoms associees\n",
    "def OHV(cl_sym,all_sym):\n",
    "    l=np.zeros([1,len(all_sym)])\n",
    "    for sym in cl_sym:\n",
    "        l[0,all_sym.index(sym)]=1\n",
    "    return pd.DataFrame(l, columns =all_symp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(small, big):\n",
    "    a=True\n",
    "    for i in small:\n",
    "        if i not in big:\n",
    "            a=False\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_diseases(l):\n",
    "    poss_dis=[]\n",
    "    for dis in set(disease):\n",
    "        if contains(l,symVONdisease(df_tr,dis)):\n",
    "            poss_dis.append(dis)\n",
    "    return poss_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoit une maladie renvoit tous les sympts\n",
    "def symVONdisease(df,disease):\n",
    "    ddf=df[df.prognosis==disease]\n",
    "    m2 = (ddf == 1).any()\n",
    "    return m2.index[m2].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symVONdisease(df_tr,'Jaundice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V- Prediction Model (KNN & DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_tr.iloc[:,:-1]\n",
    "X_test=df_tt.iloc[:,:-1]\n",
    "y_train = df_tr.iloc[:,-1]\n",
    "y_test = df_tt.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf=KNeighborsClassifier()\n",
    "knn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,knn_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,dt_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  VI- SEVERITY / DESCRIPTION / PRECAUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severityDictionary=dict()\n",
    "description_list = dict()\n",
    "precautionDictionary=dict()\n",
    "\n",
    "def getDescription():\n",
    "    global description_list\n",
    "    with open(DATASETS_DIR + 'symptom_Description.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _description={row[0]:row[1]}\n",
    "            description_list.update(_description)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getSeverityDict():\n",
    "    global severityDictionary\n",
    "    with open(DATASETS_DIR + 'symptom_severity.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        try:\n",
    "            for row in csv_reader:\n",
    "                _diction={row[0]:int(row[1])}\n",
    "                severityDictionary.update(_diction)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def getprecautionDict():\n",
    "    global precautionDictionary\n",
    "    with open(DATASETS_DIR + 'symptom_precaution.csv') as csv_file:\n",
    "\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            _prec={row[0]:[row[1],row[2],row[3],row[4]]}\n",
    "            precautionDictionary.update(_prec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSeverityDict()\n",
    "getprecautionDict()\n",
    "getDescription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severityDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_condition(exp,days):\n",
    "    sum=0\n",
    "    for item in exp:\n",
    "        if item in severityDictionary.keys():\n",
    "            sum=sum+severityDictionary[item]\n",
    "    if((sum*days)/(len(exp))>13):\n",
    "        return 1\n",
    "        print(\"You should take the consultation from doctor. \")\n",
    "    else:\n",
    "        return 0\n",
    "        print(\"It might not be that bad but you should take precautions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo():\n",
    "    # name=input(\"Name:\")\n",
    "    print(\"Your Name \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    name=input(\"\")\n",
    "    print(\"hello \",name)\n",
    "    return str(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_sym(psym1):\n",
    "    if len(psym1)==1:\n",
    "        return psym1[0]\n",
    "    print(\"searches related to input: \")\n",
    "    for num,it in enumerate(psym1):\n",
    "        print(num,\")\",clean_symp(it))\n",
    "    if num!=0:\n",
    "        print(f\"Select the one you meant (0 - {num}):  \", end=\"\")\n",
    "        conf_inp = int(input(\"\"))\n",
    "    else:\n",
    "        conf_inp=0\n",
    "\n",
    "    disease_input=psym1[conf_inp]\n",
    "    return disease_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sp(name,all_symp_col):\n",
    "    #main Idea: At least two initial sympts to start with\n",
    "    \n",
    "    #get the 1st syp ->> process it ->> check_pattern ->>> get the appropriate one (if check_pattern==1 == similar syntaxic symp found)\n",
    "    print(\"Enter the main symptom you are experiencing Mr/Ms \"+name+\"  \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    sym1 = input(\"\")\n",
    "    sym1=preprocess_sym(sym1)\n",
    "    sim1,psym1=syntactic_similarity(sym1,all_symp_pr)\n",
    "    if sim1==1:\n",
    "        psym1=related_sym(psym1)\n",
    "    \n",
    "    #get the 2nd syp ->> process it ->> check_pattern ->>> get the appropriate one (if check_pattern==1 == similar syntaxic symp found)\n",
    "\n",
    "    print(\"Enter a second symptom you are experiencing Mr/Ms \"+name+\"  \\n\\t\\t\\t\\t\\t\\t\",end=\"=>\")\n",
    "    sym2=input(\"\")\n",
    "    sym2=preprocess_sym(sym2)\n",
    "    sim2,psym2=syntactic_similarity(sym2,all_symp_pr)\n",
    "    if sim2==1:\n",
    "        psym2=related_sym(psym2)\n",
    "        \n",
    "    #if check_pattern==0 no similar syntaxic symp1 or symp2 ->> try semantic similarity\n",
    "    \n",
    "    if sim1==0 or sim2==0:\n",
    "        sim1,psym1=semantic_similarity(sym1,all_symp_pr)\n",
    "        sim2,psym2=semantic_similarity(sym2,all_symp_pr)\n",
    "        \n",
    "        #if semantic sim syp1 ==0 (no symp found) ->> suggest possible data symptoms based on all data and input sym synonymes\n",
    "        if sim1==0:\n",
    "            sugg=suggest_syn(sym1)\n",
    "            print('Are you experiencing any ')\n",
    "            for res in sugg:\n",
    "                print(res)\n",
    "                inp=input('')\n",
    "                if inp==\"yes\":\n",
    "                    psym1=res\n",
    "                    sim1=1\n",
    "                    break\n",
    "                \n",
    "        #if semantic sim syp2 ==0 (no symp found) ->> suggest possible data symptoms based on all data and input sym synonymes\n",
    "        if sim2==0:\n",
    "            sugg=suggest_syn(sym2)\n",
    "            for res in sugg:\n",
    "                inp=input('Do you feel '+ res+\" ?(yes or no) \")\n",
    "                if inp==\"yes\":\n",
    "                    psym2=res\n",
    "                    sim2=1\n",
    "                    break\n",
    "        #if no syntaxic semantic and suggested sym found return None and ask for clarification\n",
    "\n",
    "        if sim1==0 and sim2==0:\n",
    "            return None,None\n",
    "        else:\n",
    "            # if at least one sym found ->> duplicate it and proceed\n",
    "            if sim1==0:\n",
    "                psym1=psym2\n",
    "            if sim2==0:\n",
    "                psym2=psym1\n",
    "    #create patient symp list\n",
    "    all_sym=[col_dict[psym1],col_dict[psym2]]\n",
    "    #predict possible diseases\n",
    "    diseases=possible_diseases(all_sym)\n",
    "    stop=False\n",
    "    print(\"Are you experiencing any \")\n",
    "    for dis in diseases:\n",
    "        print(diseases)\n",
    "        if stop==False:\n",
    "            for sym in symVONdisease(df_tr,dis):\n",
    "                if sym not in all_sym:\n",
    "                    print(clean_symp(sym)+' ?')\n",
    "                    while True:\n",
    "                        inp=input(\"\")\n",
    "                        if(inp==\"yes\" or inp==\"no\"):\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"provide proper answers i.e. (yes/no) : \",end=\"\")\n",
    "                    if inp==\"yes\":\n",
    "                        all_sym.append(sym)\n",
    "                        diseases=possible_diseases(all_sym)\n",
    "                        if len(diseases)==1:\n",
    "                            stop=True \n",
    "    return knn_clf.predict(OHV(all_sym,all_symp_col)),all_sym\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_sp():\n",
    "    a=True\n",
    "    while a:\n",
    "        name=getInfo()\n",
    "        result,sym=main_sp(name,all_symp_col)\n",
    "        if result == None :\n",
    "            ans3=input(\"can you specify more what you feel or tap q to stop the conversation\")\n",
    "            if ans3==\"q\":\n",
    "                a=False\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            print(\"you may have \"+result[0])\n",
    "            print(description_list[result[0]])\n",
    "            an=input(\"how many day do you feel those symptoms ?\")\n",
    "            if calc_condition(sym,int(an))==1:\n",
    "                print(\"you should take the consultation from doctor\")\n",
    "            else : \n",
    "                print('Take following precautions : ')\n",
    "                for e in precautionDictionary[result[0]]:\n",
    "                    print(e)\n",
    "            print(\"do you need another medical consultation (yes or no)? \")\n",
    "            ans=input()\n",
    "            if ans!=\"yes\":\n",
    "                a=False\n",
    "                print(\"!!!!! thanks for using ower application !!!!!! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# knn_clf = joblib.load('model/knn.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symVONdisease(df_tr,\"Jaundice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.predict(OHV(['fatigue', 'weight_loss', 'itching','high_fever'],all_symp_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=df_tr[df_tr.iloc[:,-1]==\"Fungal infection\"].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=df_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=d!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl[pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[pp].drop('prognosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chat_sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
